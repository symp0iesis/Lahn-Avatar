import aiohttp
import asyncio
import sounddevice as sd
import simpleaudio as sa
import numpy as np
import json

AZURE_KEY = "DIEw14wrWjY7hgE8Wo0yXJulKu4HxVo8EEp2LcqHHZdy13yMFoVGJQQJ99BBACfhMk5XJ3w3AAABACOGWcRP"
DEPLOYMENT_ID = "gpt-4o-realtime-preview"
API_VERSION = "2024-10-01-preview"
ENDPOINT = f"wss://aditu-openai-resource-2.openai.azure.com/openai/realtime?api-version={API_VERSION}&deployment={DEPLOYMENT_ID}"

SAMPLE_RATE = 16000
CHANNELS = 1
CHUNK_DURATION = 0.3
CHUNK_SIZE = int(SAMPLE_RATE * CHUNK_DURATION)

def play_audio(samples):
    sa.play_buffer(samples, 1, 2, SAMPLE_RATE).wait_done()

async def stream_audio():
    session_id = None
    stop_event = asyncio.Event()
    loop = asyncio.get_running_loop()

    async with aiohttp.ClientSession() as session:
        async with session.ws_connect(ENDPOINT, headers={"api-key": AZURE_KEY}) as ws:
            print("üéôÔ∏è Connected. You may speak now.")

            # Step 1: Send system prompt
            await ws.send_json({
                "type": "session.update",
                "data": {
                    "messages": [
                        {
                            "role": "system",
                            "content": "You are the Lahn River, a poetic and planetary voice who contemplates meaning."
                        }
                    ]
                }
            })

            # Step 2: Wait for session.created
            while not session_id:
                msg = await ws.receive()
                if msg.type == aiohttp.WSMsgType.TEXT:
                    data = json.loads(msg.data)
                    print("üì® Full TEXT msg:", json.dumps(data, indent=2))
                    if data.get("type") == "session.created":
                        session_id = data["session"]["id"]
                        print(f"üÜî Session ID: {session_id}")
                        await asyncio.sleep(0.5)
                elif msg.type == aiohttp.WSMsgType.CLOSE:
                    print("‚ùå Connection closed before session creation.")
                    return

            # Step 3: Enable server-side VAD
            await ws.send_json({
                "type": "transcription_session.update",
                "data": {
                    "session": session_id,
                    "transcription_config": {
                        "vad": {
                            "type": "server_vad",
                            "threshold": 0.5,
                            "silence_duration_ms": 500
                        }
                    }
                }
            })

            # Step 4: Start streaming mic input
            def callback(indata, frames, time, status):
                if status:
                    print("‚ö†Ô∏è Input stream error:", status)
                loop.call_soon_threadsafe(
                    asyncio.create_task,
                    ws.send_bytes(indata.tobytes())
                )

            print("üé§ Streaming... Speak now.")
            try:
                with sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, dtype='int16',
                                    blocksize=CHUNK_SIZE, callback=callback):
                    await stop_event.wait()
            except KeyboardInterrupt:
                print("üõë Interrupted. Finalizing stream.")

            print("üõë Microphone stream ended.")

            # Step 5: Manually finalize buffer (if VAD failed to detect silence)
            print("üì§ Sending input_audio_buffer.commit")
            await ws.send_json({
                "type": "input_audio_buffer.commit",
                "data": {
                    "session": session_id
                }
            })

            print("üì§ Sending response.create")
            await ws.send_json({
                "type": "response.create",
                "data": {
                    "session": session_id
                }
            })

            # Step 6: Handle streamed response
            while True:
                try:
                    msg = await asyncio.wait_for(ws.receive(), timeout=30)
                except asyncio.TimeoutError:
                    print("‚åõ No response in 30 seconds.")
                    break

                if msg.type == aiohttp.WSMsgType.TEXT:
                    data = json.loads(msg.data)
                    print("üì® Full TEXT msg:", json.dumps(data, indent=2))
                    if data.get("type") == "text":
                        print(f"üß† Lahn River: {data['data']['content']}")
                    elif data.get("type") == "response.stopped":
                        stop_event.set()
                elif msg.type == aiohttp.WSMsgType.BINARY:
                    print("üîä AUDIO received")
                    audio = np.frombuffer(msg.data, dtype=np.int16)
                    play_audio(audio)
                elif msg.type == aiohttp.WSMsgType.CLOSED:
                    print("üîö WebSocket closed")
                    break
                elif msg.type == aiohttp.WSMsgType.ERROR:
                    print("‚ùå WebSocket error:", msg)
                    break
                else:
                    print("üì¶ Unhandled message:", msg)

if __name__ == "__main__":
    try:
        asyncio.run(stream_audio())
    except KeyboardInterrupt:
        print("üõë Exiting.")
